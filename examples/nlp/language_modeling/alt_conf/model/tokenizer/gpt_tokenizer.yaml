library: 'megatron'
type: 'GPT2BPETokenizer'
model: null
vocab_file: null
merge_file: null 
delimiter: null # only used for tabular tokenizer
sentencepiece_legacy: False # Legacy=True allows you to add special tokens to sentencepiece tokenizers.
